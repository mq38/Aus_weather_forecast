{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c86634d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
      "0  2008-12-01   Albury     13.4     22.9       0.6          NaN       NaN   \n",
      "1  2008-12-02   Albury      7.4     25.1       0.0          NaN       NaN   \n",
      "2  2008-12-03   Albury     12.9     25.7       0.0          NaN       NaN   \n",
      "3  2008-12-04   Albury      9.2     28.0       0.0          NaN       NaN   \n",
      "4  2008-12-05   Albury     17.5     32.3       1.0          NaN       NaN   \n",
      "\n",
      "  WindGustDir  WindGustSpeed WindDir9am  ... Humidity9am  Humidity3pm  \\\n",
      "0           W           44.0          W  ...        71.0         22.0   \n",
      "1         WNW           44.0        NNW  ...        44.0         25.0   \n",
      "2         WSW           46.0          W  ...        38.0         30.0   \n",
      "3          NE           24.0         SE  ...        45.0         16.0   \n",
      "4           W           41.0        ENE  ...        82.0         33.0   \n",
      "\n",
      "   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n",
      "0       1007.7       1007.1       8.0       NaN     16.9     21.8         No   \n",
      "1       1010.6       1007.8       NaN       NaN     17.2     24.3         No   \n",
      "2       1007.6       1008.7       NaN       2.0     21.0     23.2         No   \n",
      "3       1017.6       1012.8       NaN       NaN     18.1     26.5         No   \n",
      "4       1010.8       1006.0       7.0       8.0     17.8     29.7         No   \n",
      "\n",
      "   RainTomorrow  \n",
      "0            No  \n",
      "1            No  \n",
      "2            No  \n",
      "3            No  \n",
      "4            No  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "There are 7 categorical variables\n",
      "\n",
      "Categorical variables are : ['Date', 'Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday', 'RainTomorrow']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import geopandas as gpd    \n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import seaborn as sns # data visualization\n",
    "sns.reset_defaults()\n",
    "import geoplot as gplt\n",
    "from geopy.geocoders import Nominatim\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.colors as mcolors\n",
    "from scipy.interpolate import griddata\n",
    "#read data\n",
    "\n",
    "df = pd.read_csv(\"weatherAUS.csv\")\n",
    "print(df.head())\n",
    "#df.info()\n",
    "\n",
    "\n",
    "## Find categorical variables\n",
    "\n",
    "categorical = [var for var in df.columns if df[var].dtype=='O']\n",
    "\n",
    "print('There are {} categorical variables\\n'.format(len(categorical)))\n",
    "\n",
    "print('Categorical variables are :', categorical)\n",
    "\n",
    "## find missing values in categorical variables\n",
    "\n",
    "#print(df[categorical].isnull().sum())\n",
    "\n",
    "##frequency of categorical variables\n",
    "\n",
    "#for var in categorical: \n",
    "        \n",
    "#print(df[var].value_counts())\n",
    "\n",
    "##check for cardinality in categorical variables\n",
    "\n",
    "#for var in categorical:\n",
    "    \n",
    "#    print(var, ' contains ', len(df[var].unique()), ' labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17dafde9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## date variable contains 3436 labels so needs to be split into year/month/day\n",
    "\n",
    "#print(df[\"Date\"].dtypes)\n",
    "\n",
    "df['Date']= pd.to_datetime(df['Date'])\n",
    "\n",
    "df['Year'] = df['Date'].dt.year\n",
    "\n",
    "df['Month'] = df['Date'].dt.month\n",
    "\n",
    "df['Day'] = df['Date'].dt.day\n",
    "\n",
    "df.drop('Date', axis=1, inplace = True)\n",
    "\n",
    "#start looking into other categorical variables\n",
    "\n",
    "#print('Location contains', len(df.Location.unique()), 'labels')\n",
    "\n",
    "#print(df.Location.unique())\n",
    "\n",
    "#one-hot encoding for categorical variables\n",
    "\n",
    "# add most popular values for missing categorical values\n",
    "\n",
    "for df2 in [df]:\n",
    "    df2['WindGustDir'] = df2['WindGustDir'].fillna(df2['WindGustDir'].mode()[0])\n",
    "    df2['WindDir9am'] = df2['WindDir9am'].fillna(df2['WindDir9am'].mode()[0])\n",
    "    df2['WindDir3pm'] = df2['WindDir3pm'].fillna(df2['WindDir3pm'].mode()[0])\n",
    "    df2['RainToday'] = df2['RainToday'].fillna(df2['RainToday'].mode()[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca6d5e79-e107-436b-ab4c-5c3a96deed90",
   "metadata": {},
   "outputs": [],
   "source": [
    "## kaartide jaoks location vajalik\n",
    "df_map = pd.get_dummies(df, columns=[ 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday'], drop_first=True, dummy_na=True)\n",
    "\n",
    "## muude toimetuste jaoks\n",
    "df = pd.get_dummies(df, columns=['Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday'], drop_first=True, dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325b899b-7a93-42c0-84bf-51ea3f40c0c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bcfa8d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting column 'RainTomorrow' to numeric variable\n",
    "\n",
    "df['RainTomorrow'] = df['RainTomorrow'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "## Handling missing values in column 'RainTomorrow'\n",
    "df = df.dropna(subset=['RainTomorrow'])  # Drop rows with NaN in target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a541ea72-8513-48a3-bde0-ca36846bbada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinTemp             637\n",
      "MaxTemp             322\n",
      "Rainfall           1406\n",
      "Evaporation       60843\n",
      "Sunshine          67816\n",
      "                  ...  \n",
      "WindDir3pm_WNW        0\n",
      "WindDir3pm_WSW        0\n",
      "WindDir3pm_nan        0\n",
      "RainToday_Yes         0\n",
      "RainToday_nan         0\n",
      "Length: 119, dtype: int64\n",
      "        MinTemp   MaxTemp  Rainfall  Evaporation  Sunshine  WindGustSpeed  \\\n",
      "count  141556.0  141871.0  140787.0      81350.0   74377.0       132923.0   \n",
      "mean       12.0      23.0       2.0          5.0       8.0           40.0   \n",
      "std         6.0       7.0       8.0          4.0       4.0           14.0   \n",
      "min        -8.0      -5.0       0.0          0.0       0.0            6.0   \n",
      "25%         8.0      18.0       0.0          3.0       5.0           31.0   \n",
      "50%        12.0      23.0       0.0          5.0       8.0           39.0   \n",
      "75%        17.0      28.0       1.0          7.0      11.0           48.0   \n",
      "max        34.0      48.0     371.0        145.0      14.0          135.0   \n",
      "\n",
      "       WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  Pressure9am  \\\n",
      "count      140845.0      139563.0     140419.0     138583.0     128179.0   \n",
      "mean           14.0          19.0         69.0         51.0       1018.0   \n",
      "std             9.0           9.0         19.0         21.0          7.0   \n",
      "min             0.0           0.0          0.0          0.0        980.0   \n",
      "25%             7.0          13.0         57.0         37.0       1013.0   \n",
      "50%            13.0          19.0         70.0         52.0       1018.0   \n",
      "75%            19.0          24.0         83.0         66.0       1022.0   \n",
      "max           130.0          87.0        100.0        100.0       1041.0   \n",
      "\n",
      "       Pressure3pm  Cloud9am  Cloud3pm   Temp9am   Temp3pm  RainTomorrow  \\\n",
      "count     128212.0   88536.0   85099.0  141289.0  139467.0      142193.0   \n",
      "mean        1015.0       4.0       5.0      17.0      22.0           0.0   \n",
      "std            7.0       3.0       3.0       6.0       7.0           0.0   \n",
      "min          977.0       0.0       0.0      -7.0      -5.0           0.0   \n",
      "25%         1010.0       1.0       2.0      12.0      17.0           0.0   \n",
      "50%         1015.0       5.0       5.0      17.0      21.0           0.0   \n",
      "75%         1020.0       7.0       7.0      22.0      26.0           0.0   \n",
      "max         1040.0       9.0       9.0      40.0      47.0           1.0   \n",
      "\n",
      "           Year     Month       Day  \n",
      "count  142193.0  142193.0  142193.0  \n",
      "mean     2013.0       6.0      16.0  \n",
      "std         3.0       3.0       9.0  \n",
      "min      2007.0       1.0       1.0  \n",
      "25%      2011.0       3.0       8.0  \n",
      "50%      2013.0       6.0      16.0  \n",
      "75%      2015.0       9.0      23.0  \n",
      "max      2017.0      12.0      31.0   2\n"
     ]
    }
   ],
   "source": [
    "#explore numerical variables\n",
    "\n",
    "numerical = [var for var in df.columns if df[var].dtype!='O']\n",
    "\n",
    "#print('There are {} numerical variables\\n'.format(len(numerical)))\n",
    "\n",
    "#print('The numerical variables are :', numerical)\n",
    "\n",
    "#19 numerical variables, all continuous type\n",
    "#check for missing values\n",
    "\n",
    "print(df[numerical].isnull().sum())\n",
    "\n",
    "print(round(df[numerical].describe()),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85efc07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b081edfd-1a98-4a63-8b62-6e164469ed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "##plots\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "fig = df.boxplot(column='Rainfall')\n",
    "fig.set_title('')\n",
    "fig.set_ylabel('Rainfall')\n",
    "\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "fig = df.boxplot(column='Evaporation')\n",
    "fig.set_title('')\n",
    "fig.set_ylabel('Evaporation')\n",
    "\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "fig = df.boxplot(column='WindSpeed9am')\n",
    "fig.set_title('')\n",
    "fig.set_ylabel('WindSpeed9am')\n",
    "\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "fig = df.boxplot(column='WindSpeed3pm')\n",
    "fig.set_title('')\n",
    "fig.set_ylabel('WindSpeed3pm')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b248c66-c568-4044-a145-7b24ef654327",
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting into prediction stuff\n",
    "\n",
    "X = df.drop(['RainTomorrow'], axis=1)\n",
    "\n",
    "y = df['RainTomorrow']\n",
    "\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "## Replacing missing values?\n",
    "\n",
    "numerical_cols = X.select_dtypes(include=['float', 'int']).columns\n",
    "num_imputer = SimpleImputer(strategy='mean')  # Replace NaNs with mean for numerical features\n",
    "X[numerical_cols] = num_imputer.fit_transform(X[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a4e343a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((113754, 118), (28439, 118))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 15)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "908613bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8473575020218713\n",
      "[[20827  1185]\n",
      " [ 3156  3271]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.95      0.91     22012\n",
      "         1.0       0.73      0.51      0.60      6427\n",
      "\n",
      "    accuracy                           0.85     28439\n",
      "   macro avg       0.80      0.73      0.75     28439\n",
      "weighted avg       0.84      0.85      0.84     28439\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Scaling data \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "## Initializing logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "model_logreg = LogisticRegression()\n",
    "model_logreg.fit(X_train, y_train)\n",
    "\n",
    "## Predictions and evaluation\n",
    "y_pred = model_logreg.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "77c4351b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihke\\AppData\\Local\\Temp\\ipykernel_12292\\2695342618.py:13: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_filtered = df_map[(df['Year'] == 2012) & (df['Month'] == 4) & (df['Day'] == 30)].copy()\n"
     ]
    },
    {
     "ename": "IndexingError",
     "evalue": "Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcartopy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcrs\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mccrs\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcartopy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcfeature\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m df_filtered \u001b[38;5;241m=\u001b[39m df_map[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2012\u001b[39m) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMonth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDay\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m30\u001b[39m)]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# 2. Geocode the locations to get latitude and longitude\u001b[39;00m\n\u001b[0;32m     16\u001b[0m geolocator \u001b[38;5;241m=\u001b[39m Nominatim(user_agent\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeo_plotting\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4093\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[0;32m   4092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m-> 4093\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_bool_array(key)\n\u001b[0;32m   4095\u001b[0m \u001b[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[0;32m   4096\u001b[0m \u001b[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[0;32m   4097\u001b[0m is_single_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(key)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4149\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   4144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mItem wrong length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(key)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4145\u001b[0m     )\n\u001b[0;32m   4147\u001b[0m \u001b[38;5;66;03m# check_bool_indexer will throw exception if Series key cannot\u001b[39;00m\n\u001b[0;32m   4148\u001b[0m \u001b[38;5;66;03m# be reindexed to match DataFrame rows\u001b[39;00m\n\u001b[1;32m-> 4149\u001b[0m key \u001b[38;5;241m=\u001b[39m check_bool_indexer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, key)\n\u001b[0;32m   4151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m   4152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:2662\u001b[0m, in \u001b[0;36mcheck_bool_indexer\u001b[1;34m(index, key)\u001b[0m\n\u001b[0;32m   2660\u001b[0m indexer \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_indexer_for(index)\n\u001b[0;32m   2661\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01min\u001b[39;00m indexer:\n\u001b[1;32m-> 2662\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IndexingError(\n\u001b[0;32m   2663\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnalignable boolean Series provided as \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2664\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindexer (index of the boolean Series and of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2665\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe indexed object do not match).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2666\u001b[0m     )\n\u001b[0;32m   2668\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   2670\u001b[0m \u001b[38;5;66;03m# fall through for boolean\u001b[39;00m\n",
      "\u001b[1;31mIndexingError\u001b[0m: Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match)."
     ]
    }
   ],
   "source": [
    "#kaardi genemine (see on lic temperatuuride kaart kindlal ajahetkel)\n",
    "## peab kasutama df_map!!!\n",
    "\n",
    "import geopandas as gpd\n",
    "import geoplot as gplt\n",
    "import matplotlib.pyplot as plt\n",
    "from geopy.geocoders import Nominatim\n",
    "from shapely.geometry import Point\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "\n",
    "df_filtered = df_map[(df['Year'] == 2012) & (df['Month'] == 4) & (df['Day'] == 30)].copy()\n",
    "\n",
    "# 2. Geocode the locations to get latitude and longitude\n",
    "geolocator = Nominatim(user_agent=\"geo_plotting\")\n",
    "\n",
    "# Create lists to store latitudes and longitudes\n",
    "lons = []\n",
    "lats = []\n",
    "\n",
    "for location in df_filtered['Location']:\n",
    "    location_info = geolocator.geocode(location + \", Australia\")\n",
    "    if location_info:\n",
    "        lons.append(location_info.longitude)\n",
    "        lats.append(location_info.latitude)\n",
    "    else:\n",
    "        lons.append(np.nan)\n",
    "        lats.append(np.nan)\n",
    "\n",
    "# 3. Add latitude and longitude to the filtered dataframe using .loc\n",
    "df_filtered.loc[:, 'Longitude'] = lons\n",
    "df_filtered.loc[:, 'Latitude'] = lats\n",
    "\n",
    "# 4. Drop rows with NaN coordinates (e.g., missing longitude/latitude) or missing MaxTemp values\n",
    "df_filtered = df_filtered.dropna(subset=['Longitude', 'Latitude', 'MaxTemp'])\n",
    "\n",
    "# 5. Ensure lengths of coordinates and MaxTemp are the same\n",
    "lons = df_filtered['Longitude']\n",
    "lats = df_filtered['Latitude']\n",
    "temps = df_filtered['MaxTemp']\n",
    "\n",
    "# 6. Plot the locations with temperature labels\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Create a Cartopy map with PlateCarree projection (for global lat-lon coordinates)\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "# Add a natural coastline feature (cartopy feature)\n",
    "ax.add_feature(cfeature.COASTLINE, edgecolor='black')\n",
    "ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "\n",
    "# Add state boundaries for Australia\n",
    "ax.add_feature(cfeature.STATES, linestyle=':', edgecolor='gray')\n",
    "\n",
    "# Plot the location points on the map\n",
    "sc = ax.scatter(lons, lats, c=temps, cmap='coolwarm', edgecolors='k', s=100)\n",
    "\n",
    "# Add temperature labels at each location\n",
    "for idx, row in df_filtered.iterrows():\n",
    "    ax.text(row['Longitude'], row['Latitude'], f\"{row['MaxTemp']}°C\", fontsize=12, ha='center', color='black')\n",
    "\n",
    "# Add a colorbar for the temperature scale\n",
    "cbar = plt.colorbar(sc, ax=ax, label='Max Temperature (°C)')\n",
    "\n",
    "# Add labels and title\n",
    "plt.title(\"Max Temperature across Australia on 30 April 2012\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d11e2aad-175f-4962-8893-413937b26327",
   "metadata": {},
   "outputs": [],
   "source": [
    "## average max temp for all weather stations for january \n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from geopy.geocoders import Nominatim\n",
    "from shapely.geometry import Point\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "\n",
    "krige = OrdinaryKriging(lons, lats, temps, variogram_model='linear')\n",
    "\n",
    "# 1. Filter the dataset for January\n",
    "df_january = df_map[df_map['Month'] == 1].copy()\n",
    "\n",
    "# 2. Drop rows with missing temperature data\n",
    "df_january = df_january.dropna(subset=['MaxTemp'])\n",
    "\n",
    "# 3. Group by weather station and calculate the average temperature\n",
    "# Assuming 'Location' represents the weather station\n",
    "avg_temps_january = df_january.groupby('Location')['MaxTemp'].mean().reset_index()\n",
    "\n",
    "# 4. Rename columns for clarity\n",
    "avg_temps_january.columns = ['Location', 'MaxTemp']\n",
    "\n",
    "# 5. Display the result\n",
    "##print(avg_temps_january)\n",
    "\n",
    "\n",
    "# 2. Geocode the locations to get latitude and longitude\n",
    "geolocator = Nominatim(user_agent=\"geo_plotting\")\n",
    "\n",
    "# Create lists to store latitudes and longitudes\n",
    "lons = []\n",
    "lats = []\n",
    "\n",
    "for location in avg_temps_january['Location']:\n",
    "    location_info = geolocator.geocode(location + \", Australia\")\n",
    "    if location_info:\n",
    "        lons.append(location_info.longitude)\n",
    "        lats.append(location_info.latitude)\n",
    "    else:\n",
    "        lons.append(np.nan)\n",
    "        lats.append(np.nan)\n",
    "\n",
    "# Add latitude and longitude to the filtered dataframe using .loc\n",
    "avg_temps_january.loc[:, 'Longitude'] = lons\n",
    "avg_temps_january.loc[:, 'Latitude'] = lats\n",
    "\n",
    "# Drop rows with NaN coordinates or missing MaxTemp values\n",
    "avg_temps_january = avg_temps_january.dropna(subset=['Longitude', 'Latitude', 'MaxTemp'])\n",
    "\n",
    "# Extract data for interpolation\n",
    "lons = avg_temps_january['Longitude'].values\n",
    "lats = avg_temps_january['Latitude'].values\n",
    "temps = avg_temps_january['MaxTemp'].values\n",
    "\n",
    "# 3. Define a grid for interpolation\n",
    "lon_min, lon_max = lons.min() - 1, lons.max() + 1\n",
    "lat_min, lat_max = lats.min() - 1, lats.max() + 1\n",
    "lon_grid, lat_grid = np.meshgrid(\n",
    "    np.linspace(lon_min, lon_max, 200), \n",
    "    np.linspace(lat_min, lat_max, 200)\n",
    ")\n",
    "\n",
    "# 4. Interpolate temperature values onto the grid\n",
    "temp_grid, _ = krige.execute(\n",
    "    'grid', \n",
    "    np.linspace(lon_min, lon_max, 200), \n",
    "    np.linspace(lat_min, lat_max, 200)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 5. Plot the data\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Create a Cartopy map with PlateCarree projection\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "# Add map features\n",
    "ax.add_feature(cfeature.COASTLINE, edgecolor='black')\n",
    "ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "ax.add_feature(cfeature.STATES, linestyle=':', edgecolor='gray')\n",
    "\n",
    "# Plot interpolated temperature as a contour map\n",
    "contour = ax.contourf(\n",
    "    lon_grid, lat_grid, temp_grid, \n",
    "    levels=20, cmap='coolwarm', transform=ccrs.PlateCarree()\n",
    ")\n",
    "\n",
    "# Add the original data points\n",
    "sc = ax.scatter(lons, lats, c=temps, cmap='coolwarm', edgecolors='k', s=100, label='Data Points')\n",
    "\n",
    "# Add a colorbar for the temperature scale\n",
    "cbar = plt.colorbar(contour, ax=ax, orientation='vertical', label='average max Temperature (°C)')\n",
    "\n",
    "# Add labels and title\n",
    "plt.title(\"Interpolated average Max Temperature across Australia in january\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3440d797-2ae9-4a61-9c48-498240564198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#interpoleeriv kaart, pead täpsustama kuupäva df filtered all, kriging näeb hea välja\n",
    "# kasuta df_map\n",
    "#pip install pykrige\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from geopy.geocoders import Nominatim\n",
    "from shapely.geometry import Point\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "\n",
    "krige = OrdinaryKriging(lons, lats, temps, variogram_model='linear')\n",
    "\n",
    "\n",
    "# 1. Filter data for a specific date\n",
    "df_filtered = df_map[(df['Year'] == 2015) & (df['Month'] == 1) & (df['Day'] == 1)].copy()\n",
    "\n",
    "# 2. Geocode the locations to get latitude and longitude\n",
    "geolocator = Nominatim(user_agent=\"geo_plotting\")\n",
    "\n",
    "# Create lists to store latitudes and longitudes\n",
    "lons = []\n",
    "lats = []\n",
    "\n",
    "for location in df_filtered['Location']:\n",
    "    location_info = geolocator.geocode(location + \", Australia\")\n",
    "    if location_info:\n",
    "        lons.append(location_info.longitude)\n",
    "        lats.append(location_info.latitude)\n",
    "    else:\n",
    "        lons.append(np.nan)\n",
    "        lats.append(np.nan)\n",
    "\n",
    "# Add latitude and longitude to the filtered dataframe using .loc\n",
    "df_filtered.loc[:, 'Longitude'] = lons\n",
    "df_filtered.loc[:, 'Latitude'] = lats\n",
    "\n",
    "# Drop rows with NaN coordinates or missing MaxTemp values\n",
    "df_filtered = df_filtered.dropna(subset=['Longitude', 'Latitude', 'MaxTemp'])\n",
    "\n",
    "# Extract data for interpolation\n",
    "lons = df_filtered['Longitude'].values\n",
    "lats = df_filtered['Latitude'].values\n",
    "temps = df_filtered['MaxTemp'].values\n",
    "\n",
    "# 3. Define a grid for interpolation\n",
    "lon_min, lon_max = lons.min() - 1, lons.max() + 1\n",
    "lat_min, lat_max = lats.min() - 1, lats.max() + 1\n",
    "lon_grid, lat_grid = np.meshgrid(\n",
    "    np.linspace(lon_min, lon_max, 200), \n",
    "    np.linspace(lat_min, lat_max, 200)\n",
    ")\n",
    "\n",
    "# 4. Interpolate temperature values onto the grid\n",
    "temp_grid, _ = krige.execute(\n",
    "    'grid', \n",
    "    np.linspace(lon_min, lon_max, 200), \n",
    "    np.linspace(lat_min, lat_max, 200)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 5. Plot the data\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Create a Cartopy map with PlateCarree projection\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "# Add map features\n",
    "ax.add_feature(cfeature.COASTLINE, edgecolor='black')\n",
    "ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "ax.add_feature(cfeature.STATES, linestyle=':', edgecolor='gray')\n",
    "\n",
    "# Plot interpolated temperature as a contour map\n",
    "contour = ax.contourf(\n",
    "    lon_grid, lat_grid, temp_grid, \n",
    "    levels=20, cmap='coolwarm', transform=ccrs.PlateCarree()\n",
    ")\n",
    "\n",
    "# Add the original data points\n",
    "sc = ax.scatter(lons, lats, c=temps, cmap='coolwarm', edgecolors='k', s=100, label='Data Points')\n",
    "\n",
    "# Add a colorbar for the temperature scale\n",
    "cbar = plt.colorbar(contour, ax=ax, orientation='vertical', label='Max Temperature (°C)')\n",
    "\n",
    "# Add labels and title\n",
    "plt.title(\"Interpolated Max Temperature across Australia on 30 April 2012\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "185c6d90-e45e-44df-bfab-55b03e1bb002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge year month day back together\n",
    "df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
    "df = df.set_index('Date')\n",
    "\n",
    "# Drop Year, Month, Day columns if not needed\n",
    "df = df.drop(['Year', 'Month', 'Day'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "83085cc5-5738-4d9b-8e11-5018dacc9dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>WindDir3pm_SE</th>\n",
       "      <th>WindDir3pm_SSE</th>\n",
       "      <th>WindDir3pm_SSW</th>\n",
       "      <th>WindDir3pm_SW</th>\n",
       "      <th>WindDir3pm_W</th>\n",
       "      <th>WindDir3pm_WNW</th>\n",
       "      <th>WindDir3pm_WSW</th>\n",
       "      <th>WindDir3pm_nan</th>\n",
       "      <th>RainToday_Yes</th>\n",
       "      <th>RainToday_nan</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-12-01</th>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-12-02</th>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-12-03</th>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-12-04</th>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-12-05</th>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-20</th>\n",
       "      <td>3.5</td>\n",
       "      <td>21.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-21</th>\n",
       "      <td>2.8</td>\n",
       "      <td>23.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-22</th>\n",
       "      <td>3.6</td>\n",
       "      <td>25.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-23</th>\n",
       "      <td>5.4</td>\n",
       "      <td>26.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-24</th>\n",
       "      <td>7.8</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142193 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  WindGustSpeed  \\\n",
       "Date                                                                           \n",
       "2008-12-01     13.4     22.9       0.6          NaN       NaN           44.0   \n",
       "2008-12-02      7.4     25.1       0.0          NaN       NaN           44.0   \n",
       "2008-12-03     12.9     25.7       0.0          NaN       NaN           46.0   \n",
       "2008-12-04      9.2     28.0       0.0          NaN       NaN           24.0   \n",
       "2008-12-05     17.5     32.3       1.0          NaN       NaN           41.0   \n",
       "...             ...      ...       ...          ...       ...            ...   \n",
       "2017-06-20      3.5     21.8       0.0          NaN       NaN           31.0   \n",
       "2017-06-21      2.8     23.4       0.0          NaN       NaN           31.0   \n",
       "2017-06-22      3.6     25.3       0.0          NaN       NaN           22.0   \n",
       "2017-06-23      5.4     26.9       0.0          NaN       NaN           37.0   \n",
       "2017-06-24      7.8     27.0       0.0          NaN       NaN           28.0   \n",
       "\n",
       "            WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  ...  \\\n",
       "Date                                                              ...   \n",
       "2008-12-01          20.0          24.0         71.0         22.0  ...   \n",
       "2008-12-02           4.0          22.0         44.0         25.0  ...   \n",
       "2008-12-03          19.0          26.0         38.0         30.0  ...   \n",
       "2008-12-04          11.0           9.0         45.0         16.0  ...   \n",
       "2008-12-05           7.0          20.0         82.0         33.0  ...   \n",
       "...                  ...           ...          ...          ...  ...   \n",
       "2017-06-20          15.0          13.0         59.0         27.0  ...   \n",
       "2017-06-21          13.0          11.0         51.0         24.0  ...   \n",
       "2017-06-22          13.0           9.0         56.0         21.0  ...   \n",
       "2017-06-23           9.0           9.0         53.0         24.0  ...   \n",
       "2017-06-24          13.0           7.0         51.0         24.0  ...   \n",
       "\n",
       "            WindDir3pm_SE  WindDir3pm_SSE  WindDir3pm_SSW  WindDir3pm_SW  \\\n",
       "Date                                                                       \n",
       "2008-12-01          False           False           False          False   \n",
       "2008-12-02          False           False           False          False   \n",
       "2008-12-03          False           False           False          False   \n",
       "2008-12-04          False           False           False          False   \n",
       "2008-12-05          False           False           False          False   \n",
       "...                   ...             ...             ...            ...   \n",
       "2017-06-20          False           False           False          False   \n",
       "2017-06-21          False           False           False          False   \n",
       "2017-06-22          False           False           False          False   \n",
       "2017-06-23          False           False           False          False   \n",
       "2017-06-24          False           False           False          False   \n",
       "\n",
       "            WindDir3pm_W  WindDir3pm_WNW  WindDir3pm_WSW  WindDir3pm_nan  \\\n",
       "Date                                                                       \n",
       "2008-12-01         False            True           False           False   \n",
       "2008-12-02         False           False            True           False   \n",
       "2008-12-03         False           False            True           False   \n",
       "2008-12-04         False           False           False           False   \n",
       "2008-12-05         False           False           False           False   \n",
       "...                  ...             ...             ...             ...   \n",
       "2017-06-20         False           False           False           False   \n",
       "2017-06-21         False           False           False           False   \n",
       "2017-06-22         False           False           False           False   \n",
       "2017-06-23         False            True           False           False   \n",
       "2017-06-24         False           False           False           False   \n",
       "\n",
       "            RainToday_Yes  RainToday_nan  \n",
       "Date                                      \n",
       "2008-12-01          False          False  \n",
       "2008-12-02          False          False  \n",
       "2008-12-03          False          False  \n",
       "2008-12-04          False          False  \n",
       "2008-12-05          False          False  \n",
       "...                   ...            ...  \n",
       "2017-06-20          False          False  \n",
       "2017-06-21          False          False  \n",
       "2017-06-22          False          False  \n",
       "2017-06-23          False          False  \n",
       "2017-06-24          False          False  \n",
       "\n",
       "[142193 rows x 116 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5e49edb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        MinTemp_Lag_1  MaxTemp_Lag_1  Rainfall_Lag_1  MinTemp_Lag_2  \\\n",
      "0                13.4           22.9             0.6            7.4   \n",
      "1                 7.4           25.1             0.0           12.9   \n",
      "2                12.9           25.7             0.0            9.2   \n",
      "3                 9.2           28.0             0.0           17.5   \n",
      "4                17.5           32.3             1.0           14.6   \n",
      "...               ...            ...             ...            ...   \n",
      "142185            6.4           23.4             0.0            8.0   \n",
      "142186            8.0           20.7             0.0            7.4   \n",
      "142187            7.4           20.6             0.0            3.5   \n",
      "142188            3.5           21.8             0.0            2.8   \n",
      "142189            2.8           23.4             0.0            3.6   \n",
      "\n",
      "        MaxTemp_Lag_2  Rainfall_Lag_2  MinTemp_Lag_3  MaxTemp_Lag_3  \\\n",
      "0                25.1             0.0           12.9           25.7   \n",
      "1                25.7             0.0            9.2           28.0   \n",
      "2                28.0             0.0           17.5           32.3   \n",
      "3                32.3             1.0           14.6           29.7   \n",
      "4                29.7             0.2           14.3           25.0   \n",
      "...               ...             ...            ...            ...   \n",
      "142185           20.7             0.0            7.4           20.6   \n",
      "142186           20.6             0.0            3.5           21.8   \n",
      "142187           21.8             0.0            2.8           23.4   \n",
      "142188           23.4             0.0            3.6           25.3   \n",
      "142189           25.3             0.0            5.4           26.9   \n",
      "\n",
      "        Rainfall_Lag_3  Target  \n",
      "0                  0.0    28.0  \n",
      "1                  0.0    32.3  \n",
      "2                  1.0    29.7  \n",
      "3                  0.2    25.0  \n",
      "4                  0.0    26.7  \n",
      "...                ...     ...  \n",
      "142185             0.0    21.8  \n",
      "142186             0.0    23.4  \n",
      "142187             0.0    25.3  \n",
      "142188             0.0    26.9  \n",
      "142189             0.0    27.0  \n",
      "\n",
      "[142190 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "#sliding time window\n",
    "\n",
    "\n",
    "\n",
    "def create_sliding_window(df, features, window_size, forecast_horizon=1, target='MaxTemp'):\n",
    "    \"\"\"\n",
    "    Create a sliding window dataset for time series forecasting.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        features (list): List of feature column names.\n",
    "        window_size (int): Number of past time steps to include.\n",
    "        forecast_horizon (int): Number of steps ahead to predict.\n",
    "        target (str): The target column name.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Feature matrix (X).\n",
    "        pd.Series: Target variable (y).\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(len(df) - window_size - forecast_horizon + 1):\n",
    "        # Create sliding window features for the given columns\n",
    "        feature_values = df[features].iloc[i:i + window_size].values.flatten()\n",
    "        X.append(feature_values)\n",
    "        # Target is the value at the forecast horizon\n",
    "        y.append(df[target].iloc[i + window_size + forecast_horizon - 1])\n",
    "    \n",
    "    # Generate column names for features\n",
    "    feature_columns = [\n",
    "        f\"{col}_Lag_{j+1}\" for j in range(window_size) for col in features\n",
    "    ]\n",
    "    \n",
    "    return pd.DataFrame(X, columns=feature_columns), pd.Series(y, name='Target')\n",
    "\n",
    "# Parameters\n",
    "features = ['MinTemp', 'MaxTemp', 'Rainfall']\n",
    "window_size = 7  # Use past 3 days as features\n",
    "forecast_horizon = 1  # Predict 1 day ahead\n",
    "\n",
    "# Create sliding window dataset\n",
    "X, y = create_sliding_window(df, features, window_size, forecast_horizon)\n",
    "\n",
    "# Combine features and target for clarity\n",
    "sliding_window_df = pd.concat([X, y], axis=1)\n",
    "\n",
    "print(sliding_window_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b9743ad7-e6fb-486b-aa5f-01ee9d203fd7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(X, columns\u001b[38;5;241m=\u001b[39mfeature_columns), pd\u001b[38;5;241m.\u001b[39mSeries(y, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTarget\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m X, y \u001b[38;5;241m=\u001b[39m create_sliding_window(df, features, window_size)\n\u001b[1;32m---> 14\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X, y)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Predict for 10th February 2015\u001b[39;00m\n\u001b[0;32m     17\u001b[0m target_date \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mTimestamp(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2015-02-10\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:609\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    605\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    607\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 609\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    610\u001b[0m     X,\n\u001b[0;32m    611\u001b[0m     y,\n\u001b[0;32m    612\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m    613\u001b[0m     y_numeric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    614\u001b[0m     multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    615\u001b[0m     force_writeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    616\u001b[0m )\n\u001b[0;32m    618\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    619\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1301\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1296\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1299\u001b[0m     )\n\u001b[1;32m-> 1301\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1302\u001b[0m     X,\n\u001b[0;32m   1303\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   1304\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[0;32m   1305\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1306\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[0;32m   1307\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1308\u001b[0m     force_writeable\u001b[38;5;241m=\u001b[39mforce_writeable,\n\u001b[0;32m   1309\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m   1310\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m   1311\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[0;32m   1312\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[0;32m   1313\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[0;32m   1314\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1315\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1316\u001b[0m )\n\u001b[0;32m   1318\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1320\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1064\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1061\u001b[0m     )\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m-> 1064\u001b[0m     _assert_all_finite(\n\u001b[0;32m   1065\u001b[0m         array,\n\u001b[0;32m   1066\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m   1067\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m   1068\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1069\u001b[0m     )\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1073\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:123\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m _assert_all_finite_element_wise(\n\u001b[0;32m    124\u001b[0m     X,\n\u001b[0;32m    125\u001b[0m     xp\u001b[38;5;241m=\u001b[39mxp,\n\u001b[0;32m    126\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n\u001b[0;32m    127\u001b[0m     msg_dtype\u001b[38;5;241m=\u001b[39mmsg_dtype,\n\u001b[0;32m    128\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    129\u001b[0m     input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    130\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:172\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    171\u001b[0m     )\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "def create_sliding_window(df, features, window_size, forecast_horizon=1, target='MaxTemp'):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window_size - forecast_horizon + 1):\n",
    "        feature_values = df[features].iloc[i:i + window_size].values.flatten()\n",
    "        X.append(feature_values)\n",
    "        y.append(df[target].iloc[i + window_size + forecast_horizon - 1])\n",
    "    feature_columns = [\n",
    "        f\"{col}_Lag_{j+1}\" for j in range(window_size) for col in features\n",
    "    ]\n",
    "    return pd.DataFrame(X, columns=feature_columns), pd.Series(y, name='Target')\n",
    "\n",
    "X, y = create_sliding_window(df, features, window_size)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict for 10th February 2015\n",
    "target_date = pd.Timestamp('2015-02-10')\n",
    "\n",
    "# Ensure we have enough data before the target date\n",
    "if target_date not in df.index:\n",
    "    raise ValueError(f\"Target date {target_date} is not in the dataset.\")\n",
    "start_date = target_date - pd.Timedelta(days=window_size)\n",
    "if start_date not in df.index:\n",
    "    raise ValueError(f\"Insufficient data to create sliding window for {target_date}.\")\n",
    "\n",
    "# Extract past window_size days of data\n",
    "input_features = df.loc[start_date:target_date - pd.Timedelta(days=1), features].values.flatten()\n",
    "\n",
    "# Ensure input length matches the model's expected input shape\n",
    "if len(input_features) != window_size * len(features):\n",
    "    raise ValueError(f\"Insufficient data to create sliding window for {target_date}.\")\n",
    "\n",
    "# Make the prediction\n",
    "predicted_value = model.predict([input_features])[0]\n",
    "print(f\"Predicted MaxTemp for {target_date.date()}: {predicted_value:.2f}°C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9f441b-40f2-4a12-b500-bbd8f113404f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
