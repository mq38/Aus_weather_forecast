{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c70384ab",
   "metadata": {},
   "source": [
    "# Predicting weather in Australia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710d3b14",
   "metadata": {},
   "source": [
    "## 1. Importing libraries/data and encoding variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c86634d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
      "0  2008-12-01   Albury     13.4     22.9       0.6          NaN       NaN   \n",
      "1  2008-12-02   Albury      7.4     25.1       0.0          NaN       NaN   \n",
      "2  2008-12-03   Albury     12.9     25.7       0.0          NaN       NaN   \n",
      "3  2008-12-04   Albury      9.2     28.0       0.0          NaN       NaN   \n",
      "4  2008-12-05   Albury     17.5     32.3       1.0          NaN       NaN   \n",
      "\n",
      "  WindGustDir  WindGustSpeed WindDir9am  ... Humidity9am  Humidity3pm  \\\n",
      "0           W           44.0          W  ...        71.0         22.0   \n",
      "1         WNW           44.0        NNW  ...        44.0         25.0   \n",
      "2         WSW           46.0          W  ...        38.0         30.0   \n",
      "3          NE           24.0         SE  ...        45.0         16.0   \n",
      "4           W           41.0        ENE  ...        82.0         33.0   \n",
      "\n",
      "   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n",
      "0       1007.7       1007.1       8.0       NaN     16.9     21.8         No   \n",
      "1       1010.6       1007.8       NaN       NaN     17.2     24.3         No   \n",
      "2       1007.6       1008.7       NaN       2.0     21.0     23.2         No   \n",
      "3       1017.6       1012.8       NaN       NaN     18.1     26.5         No   \n",
      "4       1010.8       1006.0       7.0       8.0     17.8     29.7         No   \n",
      "\n",
      "   RainTomorrow  \n",
      "0            No  \n",
      "1            No  \n",
      "2            No  \n",
      "3            No  \n",
      "4            No  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "There are 7 categorical variables\n",
      "\n",
      "Categorical variables are : ['Date', 'Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday', 'RainTomorrow']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import geopandas as gpd    \n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import seaborn as sns # data visualization\n",
    "sns.reset_defaults()\n",
    "import geoplot as gplt\n",
    "from geopy.geocoders import Nominatim\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.colors as mcolors\n",
    "from scipy.interpolate import griddata\n",
    "#read data\n",
    "\n",
    "df = pd.read_csv(\"weatherAUS.csv\")\n",
    "print(df.head())\n",
    "#df.info()\n",
    "\n",
    "\n",
    "## Find categorical variables\n",
    "\n",
    "categorical = [var for var in df.columns if df[var].dtype=='O']\n",
    "\n",
    "print('There are {} categorical variables\\n'.format(len(categorical)))\n",
    "\n",
    "print('Categorical variables are :', categorical)\n",
    "\n",
    "## find missing values in categorical variables\n",
    "\n",
    "#print(df[categorical].isnull().sum())\n",
    "\n",
    "##frequency of categorical variables\n",
    "\n",
    "#for var in categorical: \n",
    "        \n",
    "#print(df[var].value_counts())\n",
    "\n",
    "##check for cardinality in categorical variables\n",
    "\n",
    "#for var in categorical:\n",
    "    \n",
    "#    print(var, ' contains ', len(df[var].unique()), ' labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17dafde9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## date variable contains 3436 labels so needs to be split into year/month/day\n",
    "\n",
    "#print(df[\"Date\"].dtypes)\n",
    "\n",
    "df['Date']= pd.to_datetime(df['Date'])\n",
    "\n",
    "df['Year'] = df['Date'].dt.year\n",
    "\n",
    "df['Month'] = df['Date'].dt.month\n",
    "\n",
    "df['Day'] = df['Date'].dt.day\n",
    "\n",
    "df.drop('Date', axis=1, inplace = True)\n",
    "\n",
    "#start looking into other categorical variables\n",
    "\n",
    "#print('Location contains', len(df.Location.unique()), 'labels')\n",
    "\n",
    "#print(df.Location.unique())\n",
    "\n",
    "#one-hot encoding for categorical variables\n",
    "\n",
    "# add most popular values for missing categorical values\n",
    "\n",
    "for df2 in [df]:\n",
    "    df2['WindGustDir'] = df2['WindGustDir'].fillna(df2['WindGustDir'].mode()[0])\n",
    "    df2['WindDir9am'] = df2['WindDir9am'].fillna(df2['WindDir9am'].mode()[0])\n",
    "    df2['WindDir3pm'] = df2['WindDir3pm'].fillna(df2['WindDir3pm'].mode()[0])\n",
    "    df2['RainToday'] = df2['RainToday'].fillna(df2['RainToday'].mode()[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca6d5e79-e107-436b-ab4c-5c3a96deed90",
   "metadata": {},
   "outputs": [],
   "source": [
    "## location is necessary for maps, so this is omitted as a dummy variable from df_map\n",
    "df_map = pd.get_dummies(df, columns=[ 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday'], drop_first=True, dummy_na=True)\n",
    "\n",
    "## for other needs\n",
    "df = pd.get_dummies(df, columns=['Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday'], drop_first=True, dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a541ea72-8513-48a3-bde0-ca36846bbada",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinTemp            1485\n",
      "MaxTemp            1261\n",
      "Rainfall           3261\n",
      "Evaporation       62790\n",
      "Sunshine          69835\n",
      "                  ...  \n",
      "WindDir3pm_WNW        0\n",
      "WindDir3pm_WSW        0\n",
      "WindDir3pm_nan        0\n",
      "RainToday_Yes         0\n",
      "RainToday_nan         0\n",
      "Length: 118, dtype: int64\n",
      "        MinTemp   MaxTemp  Rainfall  Evaporation  Sunshine  WindGustSpeed  \\\n",
      "count  143975.0  144199.0  142199.0      82670.0   75625.0       135197.0   \n",
      "mean       12.0      23.0       2.0          5.0       8.0           40.0   \n",
      "std         6.0       7.0       8.0          4.0       4.0           14.0   \n",
      "min        -8.0      -5.0       0.0          0.0       0.0            6.0   \n",
      "25%         8.0      18.0       0.0          3.0       5.0           31.0   \n",
      "50%        12.0      23.0       0.0          5.0       8.0           39.0   \n",
      "75%        17.0      28.0       1.0          7.0      11.0           48.0   \n",
      "max        34.0      48.0     371.0        145.0      14.0          135.0   \n",
      "\n",
      "       WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  Pressure9am  \\\n",
      "count      143693.0      142398.0     142806.0     140953.0     130395.0   \n",
      "mean           14.0          19.0         69.0         52.0       1018.0   \n",
      "std             9.0           9.0         19.0         21.0          7.0   \n",
      "min             0.0           0.0          0.0          0.0        980.0   \n",
      "25%             7.0          13.0         57.0         37.0       1013.0   \n",
      "50%            13.0          19.0         70.0         52.0       1018.0   \n",
      "75%            19.0          24.0         83.0         66.0       1022.0   \n",
      "max           130.0          87.0        100.0        100.0       1041.0   \n",
      "\n",
      "       Pressure3pm  Cloud9am  Cloud3pm   Temp9am   Temp3pm      Year  \\\n",
      "count     130432.0   89572.0   86102.0  143693.0  141851.0  145460.0   \n",
      "mean        1015.0       4.0       5.0      17.0      22.0    2013.0   \n",
      "std            7.0       3.0       3.0       6.0       7.0       3.0   \n",
      "min          977.0       0.0       0.0      -7.0      -5.0    2007.0   \n",
      "25%         1010.0       1.0       2.0      12.0      17.0    2011.0   \n",
      "50%         1015.0       5.0       5.0      17.0      21.0    2013.0   \n",
      "75%         1020.0       7.0       7.0      22.0      26.0    2015.0   \n",
      "max         1040.0       9.0       9.0      40.0      47.0    2017.0   \n",
      "\n",
      "          Month       Day  \n",
      "count  145460.0  145460.0  \n",
      "mean        6.0      16.0  \n",
      "std         3.0       9.0  \n",
      "min         1.0       1.0  \n",
      "25%         3.0       8.0  \n",
      "50%         6.0      16.0  \n",
      "75%         9.0      23.0  \n",
      "max        12.0      31.0   2\n"
     ]
    }
   ],
   "source": [
    "# explore numerical variables\n",
    "\n",
    "numerical = [var for var in df.columns if df[var].dtype!='O']\n",
    "\n",
    "#print('There are {} numerical variables\\n'.format(len(numerical)))\n",
    "\n",
    "#print('The numerical variables are :', numerical)\n",
    "\n",
    "#19 numerical variables, all continuous type\n",
    "#check for missing values\n",
    "\n",
    "print(df[numerical].isnull().sum())\n",
    "\n",
    "print(round(df[numerical].describe()),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332e8cb1",
   "metadata": {},
   "source": [
    "## 2. Plotting weather variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b081edfd-1a98-4a63-8b62-6e164469ed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "##plots\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "fig = df.boxplot(column='Rainfall')\n",
    "fig.set_title('')\n",
    "fig.set_ylabel('Rainfall')\n",
    "\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "fig = df.boxplot(column='Evaporation')\n",
    "fig.set_title('')\n",
    "fig.set_ylabel('Evaporation')\n",
    "\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "fig = df.boxplot(column='WindSpeed9am')\n",
    "fig.set_title('')\n",
    "fig.set_ylabel('WindSpeed9am')\n",
    "\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "fig = df.boxplot(column='WindSpeed3pm')\n",
    "fig.set_title('')\n",
    "fig.set_ylabel('WindSpeed3pm')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764ad039",
   "metadata": {},
   "source": [
    "## 3. Prediction of rain tomorrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcfa8d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "## converting column 'RainTomorrow' to numeric variable\n",
    "\n",
    "df['RainTomorrow'] = df['RainTomorrow'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "## handling missing values in column 'RainTomorrow'\n",
    "df = df.dropna(subset=['RainTomorrow'])  # dropping rows with NaN in 'RainTomorrow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b248c66-c568-4044-a145-7b24ef654327",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating dataframes with and without target \n",
    "\n",
    "X = df.drop(['RainTomorrow'], axis=1)\n",
    "\n",
    "y = df['RainTomorrow']\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "## replacing missing values with mean for imputation\n",
    "\n",
    "num_cols = X.select_dtypes(include=['float', 'int']).columns\n",
    "num_imputer = SimpleImputer(strategy='mean')  # replacing NaNs with mean for numerical features\n",
    "X[num_cols] = num_imputer.fit_transform(X[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4e343a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## splitting data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "908613bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7963711804212525\n",
      "[[17632  4380]\n",
      " [ 1411  5016]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.80      0.86     22012\n",
      "         1.0       0.53      0.78      0.63      6427\n",
      "\n",
      "    accuracy                           0.80     28439\n",
      "   macro avg       0.73      0.79      0.75     28439\n",
      "weighted avg       0.84      0.80      0.81     28439\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## scaling data \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "## initializing logistic regression model --> as we have binary classification task\n",
    "## logistic regression assumes linear relationship between variables\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "model_logreg = LogisticRegression(class_weight='balanced', C=0.1, solver='lbfgs')\n",
    "model_logreg.fit(X_train, y_train)\n",
    "\n",
    "## predictions and evaluation\n",
    "y_pred = model_logreg.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54de1ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "## finding the best parameters for logistic regression model\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'solver': ['liblinear', 'lbfgs']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(class_weight='balanced'), param_grid, cv=5, scoring='f1_macro')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bcc108",
   "metadata": {},
   "source": [
    "## 4. Creating maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96eda74",
   "metadata": {},
   "source": [
    "### 4.1 Example temperature map for April 30th, 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77c4351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kaardi genemine (see on lic temperatuuride kaart kindlal ajahetkel)\n",
    "## peab kasutama df_map!!!\n",
    "\n",
    "import geopandas as gpd\n",
    "import geoplot as gplt\n",
    "import matplotlib.pyplot as plt\n",
    "from geopy.geocoders import Nominatim\n",
    "from shapely.geometry import Point\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "# filter data for the specific date\n",
    "df_filtered = df_map[(df_map['Year'] == 2012) & (df_map['Month'] == 4) & (df_map['Day'] == 30)].copy()\n",
    "\n",
    "# geocode the locations to get latitude and longitude\n",
    "geolocator = Nominatim(user_agent=\"geo_plotting\")\n",
    "\n",
    "# Create lists to store latitudes and longitudes\n",
    "lons = []\n",
    "lats = []\n",
    "\n",
    "for location in df_filtered['Location']:\n",
    "    location_info = geolocator.geocode(location + \", Australia\")\n",
    "    if location_info:\n",
    "        lons.append(location_info.longitude)\n",
    "        lats.append(location_info.latitude)\n",
    "    else:\n",
    "        lons.append(np.nan)\n",
    "        lats.append(np.nan)\n",
    "\n",
    "# 3. Add latitude and longitude to the filtered dataframe\n",
    "df_filtered.loc[:, 'Longitude'] = lons\n",
    "df_filtered.loc[:, 'Latitude'] = lats\n",
    "\n",
    "# 4. Drop rows with missing coordinates or temperature data\n",
    "df_filtered = df_filtered.dropna(subset=['Longitude', 'Latitude', 'MaxTemp'])\n",
    "\n",
    "# 5. Extract columns for plotting\n",
    "lons = df_filtered['Longitude']\n",
    "lats = df_filtered['Latitude']\n",
    "temps = df_filtered['MaxTemp']\n",
    "\n",
    "# 6. Create the map plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Create a Cartopy map with PlateCarree projection\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "# Add map features\n",
    "ax.add_feature(cfeature.COASTLINE, edgecolor='black')\n",
    "ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "ax.add_feature(cfeature.STATES, linestyle=':', edgecolor='gray')\n",
    "\n",
    "# Plot temperature points\n",
    "sc = ax.scatter(lons, lats, c=temps, cmap='coolwarm', edgecolors='k', s=100)\n",
    "\n",
    "# Add temperature labels\n",
    "for idx, row in df_filtered.iterrows():\n",
    "    ax.text(row['Longitude'], row['Latitude'] + 0.2, f\"{row['MaxTemp']}°C\", fontsize=10, ha='center', color='black')  # Temp above the point\n",
    "    ax.text(row['Longitude'], row['Latitude'] - 0.2, row['Location'], fontsize=9, ha='center', color='blue')         # Location below the point\n",
    "\n",
    "\n",
    "# Add a colorbar\n",
    "cbar = plt.colorbar(sc, ax=ax, orientation='vertical', label='Max Temperature (°C)')\n",
    "\n",
    "# Add labels and title\n",
    "plt.title(\"Max Temperature across Australia on 30 April 2012\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38661dc1",
   "metadata": {},
   "source": [
    "### 4.2 Average max temp for all weather stations for january "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2baab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pykrige"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d11e2aad-175f-4962-8893-413937b26327",
   "metadata": {},
   "outputs": [],
   "source": [
    "## next map is better for the poster\n",
    "\n",
    "## average max temp for all weather stations for january \n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from geopy.geocoders import Nominatim\n",
    "from shapely.geometry import Point\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "\n",
    "krige = OrdinaryKriging(lons, lats, temps, variogram_model='linear')\n",
    "\n",
    "# filter the dataset for January\n",
    "df_january = df_map[df_map['Month'] == 1].copy()\n",
    "\n",
    "# drop rows with missing temperature data\n",
    "df_january = df_january.dropna(subset=['MaxTemp'])\n",
    "\n",
    "# group by weather station and calculate the average temperature\n",
    "# Assuming 'Location' represents the weather station\n",
    "avg_temps_january = df_january.groupby('Location')['MaxTemp'].mean().reset_index()\n",
    "\n",
    "# rename columns for clarity\n",
    "avg_temps_january.columns = ['Location', 'MaxTemp']\n",
    "\n",
    "# display the result\n",
    "##print(avg_temps_january)\n",
    "\n",
    "\n",
    "# geocode the locations to get latitude and longitude\n",
    "geolocator = Nominatim(user_agent=\"geo_plotting\")\n",
    "\n",
    "# create lists to store latitudes and longitudes\n",
    "lons = []\n",
    "lats = []\n",
    "\n",
    "for location in avg_temps_january['Location']:\n",
    "    location_info = geolocator.geocode(location + \", Australia\")\n",
    "    if location_info:\n",
    "        lons.append(location_info.longitude)\n",
    "        lats.append(location_info.latitude)\n",
    "    else:\n",
    "        lons.append(np.nan)\n",
    "        lats.append(np.nan)\n",
    "\n",
    "# add latitude and longitude to the filtered dataframe using .loc\n",
    "avg_temps_january.loc[:, 'Longitude'] = lons\n",
    "avg_temps_january.loc[:, 'Latitude'] = lats\n",
    "\n",
    "# drop rows with NaN coordinates or missing MaxTemp values\n",
    "avg_temps_january = avg_temps_january.dropna(subset=['Longitude', 'Latitude', 'MaxTemp'])\n",
    "\n",
    "# extract data for interpolation\n",
    "lons = avg_temps_january['Longitude'].values\n",
    "lats = avg_temps_january['Latitude'].values\n",
    "temps = avg_temps_january['MaxTemp'].values\n",
    "\n",
    "# define a grid for interpolation\n",
    "lon_min, lon_max = lons.min() - 1, lons.max() + 1\n",
    "lat_min, lat_max = lats.min() - 1, lats.max() + 1\n",
    "lon_grid, lat_grid = np.meshgrid(\n",
    "    np.linspace(lon_min, lon_max, 200), \n",
    "    np.linspace(lat_min, lat_max, 200)\n",
    ")\n",
    "\n",
    "# interpolate temperature values onto the grid\n",
    "temp_grid, _ = krige.execute(\n",
    "    'grid', \n",
    "    np.linspace(lon_min, lon_max, 200), \n",
    "    np.linspace(lat_min, lat_max, 200)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# plot the data\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# create a Cartopy map with PlateCarree projection\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "# add map features\n",
    "ax.add_feature(cfeature.COASTLINE, edgecolor='black')\n",
    "ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "ax.add_feature(cfeature.STATES, linestyle=':', edgecolor='gray')\n",
    "\n",
    "# plot interpolated temperature as a contour map\n",
    "contour = ax.contourf(\n",
    "    lon_grid, lat_grid, temp_grid, \n",
    "    levels=20, cmap='coolwarm', transform=ccrs.PlateCarree()\n",
    ")\n",
    "\n",
    "sc = ax.scatter(\n",
    "    lons, lats, color='black', edgecolors='k', s=100, label='Data Points'\n",
    ")\n",
    "\n",
    "# add location labels\n",
    "for idx, row in avg_temps_january.iterrows():\n",
    "    ax.text(\n",
    "        row['Longitude'], row['Latitude'] + 0.5,  # Slightly offset above each point\n",
    "        row['Location'], fontsize=9, ha='center', color='green'\n",
    "    )\n",
    "\n",
    "\n",
    "# add labels and title\n",
    "plt.title(\"Interpolated average max. temperature across Australia in January\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6242de3",
   "metadata": {},
   "source": [
    "### 4.3 Interpolation map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3440d797-2ae9-4a61-9c48-498240564198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# läheb postrile\n",
    "#interpoleeriv kaart, pead täpsustama kuupäeva df filtered all, kriging näeb hea välja\n",
    "# kasuta df_map\n",
    "# pip install pykrige\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from geopy.geocoders import Nominatim\n",
    "from shapely.geometry import Point\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "\n",
    "krige = OrdinaryKriging(lons, lats, temps, variogram_model='linear')\n",
    "\n",
    "\n",
    "# 1. Filter data for a specific date\n",
    "df_filtered = df_map[(df_map['Year'] == 2015) & (df_map['Month'] == 7) & (df_map['Day'] == 8)].copy()\n",
    "\n",
    "# 2. Geocode the locations to get latitude and longitude\n",
    "geolocator = Nominatim(user_agent=\"geo_plotting\")\n",
    "\n",
    "# Create lists to store latitudes and longitudes\n",
    "lons = []\n",
    "lats = []\n",
    "\n",
    "for location in df_filtered['Location']:\n",
    "    location_info = geolocator.geocode(location + \", Australia\")\n",
    "    if location_info:\n",
    "        lons.append(location_info.longitude)\n",
    "        lats.append(location_info.latitude)\n",
    "    else:\n",
    "        lons.append(np.nan)\n",
    "        lats.append(np.nan)\n",
    "\n",
    "# Add latitude and longitude to the filtered dataframe using .loc\n",
    "df_filtered.loc[:, 'Longitude'] = lons\n",
    "df_filtered.loc[:, 'Latitude'] = lats\n",
    "\n",
    "# Drop rows with NaN coordinates or missing MaxTemp values\n",
    "df_filtered = df_filtered.dropna(subset=['Longitude', 'Latitude', 'MaxTemp'])\n",
    "\n",
    "# Extract data for interpolation\n",
    "lons = df_filtered['Longitude'].values\n",
    "lats = df_filtered['Latitude'].values\n",
    "temps = df_filtered['MaxTemp'].values\n",
    "\n",
    "# 3. Define a grid for interpolation\n",
    "lon_min, lon_max = lons.min() - 1, lons.max() + 1\n",
    "lat_min, lat_max = lats.min() - 1, lats.max() + 1\n",
    "lon_grid, lat_grid = np.meshgrid(\n",
    "    np.linspace(lon_min, lon_max, 200), \n",
    "    np.linspace(lat_min, lat_max, 200)\n",
    ")\n",
    "\n",
    "# 4. Interpolate temperature values onto the grid\n",
    "temp_grid, _ = krige.execute(\n",
    "    'grid', \n",
    "    np.linspace(lon_min, lon_max, 200), \n",
    "    np.linspace(lat_min, lat_max, 200)\n",
    ")\n",
    "\n",
    "\n",
    "# 5. Plot the data\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Create a Cartopy map with PlateCarree projection\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "# Add map features\n",
    "ax.add_feature(cfeature.COASTLINE, edgecolor='black')\n",
    "ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "ax.add_feature(cfeature.STATES, linestyle=':', edgecolor='gray')\n",
    "\n",
    "# Plot interpolated temperature as a contour map\n",
    "contour = ax.contourf(\n",
    "    lon_grid, lat_grid, temp_grid, \n",
    "    levels=20, cmap='coolwarm', transform=ccrs.PlateCarree()\n",
    ")\n",
    "\n",
    "# Add the original data points\n",
    "sc = ax.scatter(lons, lats, edgecolors='k', s=100, label='Location')\n",
    "\n",
    "# Add a colorbar for the temperature scale\n",
    "cbar = plt.colorbar(contour, ax=ax, orientation='vertical', label='Max Temperature (°C)')\n",
    "\n",
    "# Add labels and title\n",
    "plt.title(\"Interpolated Max Temperature across Australia \")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "185c6d90-e45e-44df-bfab-55b03e1bb002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge year month day back together\n",
    "df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
    "\n",
    "# Drop Year, Month, Day columns if not needed\n",
    "df = df.drop(['Year', 'Month', 'Day'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "deadbaa3-c3ad-4284-ac58-e777eb8543a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = df.select_dtypes(include=['float', 'int']).columns\n",
    "num_imputer = SimpleImputer(strategy='mean')  # Replace NaNs with mean for numerical features\n",
    "df[numerical_cols] = num_imputer.fit_transform(df[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83085cc5-5738-4d9b-8e11-5018dacc9dbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Day'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3805\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3806\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Day'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16160\\2484993694.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Day'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4101\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4102\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4103\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3810\u001b[0m             ):\n\u001b[0;32m   3811\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3812\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3813\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3814\u001b[0m             \u001b[1;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Day'"
     ]
    }
   ],
   "source": [
    "df['Day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e48b04-2f2e-455f-8abc-12eae91de467",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e7ad95-36ce-48c2-aeed-ed234a6ca1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values=df_map['Location'].unique()\n",
    "unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdca060-f1c5-43ce-b6be-2a87ff418f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[['Year', 'Month', 'Day']].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8c4ff0-ec86-4a0e-8b37-72fad2e00d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def predict_weather_by_location(df, year, month, day, location, window_size=7):\n",
    "    \"\"\"\n",
    "    Predict MaxTemp, MinTemp, and Rainfall for a specified date and location \n",
    "    using the last `window_size` days as input.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame with 'Date', 'Location', and columns ['MinTemp', 'MaxTemp', 'Rainfall'].\n",
    "    - year (int): Year of the target prediction date.\n",
    "    - month (int): Month of the target prediction date.\n",
    "    - day (int): Day of the target prediction date.\n",
    "    - location (str): Location for which to predict the weather.\n",
    "    - window_size (int): Number of past days to use as input features.\n",
    "\n",
    "    Returns:\n",
    "    - dict: Predicted values for MaxTemp, MinTemp, and Rainfall.\n",
    "    \"\"\"\n",
    "    # Ensure required columns exist\n",
    "    required_columns = ['Date', 'Location', 'MinTemp', 'MaxTemp', 'Rainfall']\n",
    "    if not all(col in df.columns for col in required_columns):\n",
    "        raise ValueError(f\"DataFrame must contain the columns: {required_columns}\")\n",
    "    \n",
    "    # Ensure 'Date' column is datetime64 dtype\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df['Date']):\n",
    "        raise ValueError(\"Ensure 'Date' column is preprocessed as datetime64 dtype.\")\n",
    "    \n",
    "    # Filter data for the specified location\n",
    "    df_location = df[df['Location'] == location].copy()\n",
    "    if df_location.empty:\n",
    "        raise ValueError(f\"No data found for location '{location}'.\")\n",
    "\n",
    "    # Ensure the target date exists in the filtered data\n",
    "    target_date_str = f\"{year:04d}-{month:02d}-{day:02d}\"\n",
    "    target_date = pd.to_datetime(target_date_str)\n",
    "    if target_date not in df_location['Date'].values:\n",
    "        raise ValueError(f\"Target date {target_date_str} is not in the dataset for location '{location}'.\")\n",
    "\n",
    "    # Sort the data by date\n",
    "    df_location = df_location.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "    # Get the target index and check window size availability\n",
    "    target_index = df_location.index[df_location['Date'] == target_date][0]\n",
    "    start_index = target_index - window_size\n",
    "    if start_index < 0:\n",
    "        raise ValueError(f\"Insufficient data to create sliding window for {target_date_str} at location '{location}'.\")\n",
    "\n",
    "    # Extract sliding window data\n",
    "    feature_columns = ['MinTemp', 'MaxTemp', 'Rainfall']\n",
    "    past_data = df_location[feature_columns].iloc[start_index:target_index].to_numpy()\n",
    "    input_features = past_data.flatten()\n",
    "\n",
    "    # Generate features for training\n",
    "    X = []\n",
    "    y = {col: [] for col in feature_columns}\n",
    "    for i in range(window_size, len(df_location)):\n",
    "        X.append(df_location[feature_columns].iloc[i - window_size:i].to_numpy().flatten())\n",
    "        for col in feature_columns:\n",
    "            y[col].append(df_location[col].iloc[i])\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = {col: np.array(vals) for col, vals in y.items()}\n",
    "\n",
    "    # Train models for each target variable\n",
    "    models = {}\n",
    "    for col in feature_columns:\n",
    "        model = LinearRegression()\n",
    "        model.fit(X, y[col])\n",
    "        models[col] = model\n",
    "\n",
    "    # Predict the target values\n",
    "    predictions = {}\n",
    "    for col, model in models.items():\n",
    "        predictions[col] = model.predict([input_features])[0]\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Example Usage\n",
    "\n",
    "#df['Date'] = pd.to_datetime(df['Date'])  # Pre-convert 'Date' column to datetime\n",
    "\n",
    "# Predict for Sydney on 10th February 2015\n",
    "predicted_values = predict_weather_by_location(df, 2015, 5, 10, 'Sydney')\n",
    "print(f\"Predictions for Sydney on 2015-02-10: {predicted_values}\")\n",
    "\n",
    "# Predict for Melbourne on 15th February 2015\n",
    "predicted_values = predict_weather_by_location(df, 2015, 5, 10, 'Albury')\n",
    "print(f\"Predictions for Albury on 2015-02-15: {predicted_values}\")\n",
    "\n",
    "\n",
    "#loe kokku ühte df-i ja tee kaart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344863a6-c7d0-4d38-b9fc-987ce0f44260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_weather_for_all_locations(df, year, month, day, window_size=7):\n",
    "    \"\"\"\n",
    "    Predict MaxTemp, MinTemp, and Rainfall for a specified date across all locations.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame with 'Date', 'Location', and columns ['MinTemp', 'MaxTemp', 'Rainfall'].\n",
    "    - year (int): Year of the target prediction date.\n",
    "    - month (int): Month of the target prediction date.\n",
    "    - day (int): Day of the target prediction date.\n",
    "    - window_size (int): Number of past days to use as input features.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame containing predictions for all locations.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    target_date_str = f\"{year:04d}-{month:02d}-{day:02d}\"\n",
    "    \n",
    "    # Iterate over all unique locations in the DataFrame\n",
    "    for location in df['Location'].unique():\n",
    "        try:\n",
    "            # Use the predict_weather_by_location function for each location\n",
    "            prediction = predict_weather_by_location(df, year, month, day, location, window_size)\n",
    "            # Append the results with location and target date info\n",
    "            results.append({\n",
    "                'Location': location,\n",
    "                'Date': target_date_str,\n",
    "                **prediction\n",
    "            })\n",
    "        except ValueError as e:\n",
    "            print(f\"Skipping location '{location}': {e}\")\n",
    "\n",
    "    # Convert results to a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n",
    "\n",
    "# Example Usage\n",
    "\n",
    "\n",
    "predictions_df = predict_weather_for_all_locations(df, 2013, 1, 10)\n",
    "\n",
    "# Display results\n",
    "print(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c9823d-e119-45ed-8681-a16c4282d1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "# Geocoding\n",
    "geolocator = Nominatim(user_agent=\"geo_plotting\")\n",
    "lons = []\n",
    "lats = []\n",
    "\n",
    "for location in predictions_df['Location']:\n",
    "    location_info = geolocator.geocode(location + \", Australia\")\n",
    "    if location_info:\n",
    "        lons.append(location_info.longitude)\n",
    "        lats.append(location_info.latitude)\n",
    "    else:\n",
    "        lons.append(np.nan)\n",
    "        lats.append(np.nan)\n",
    "\n",
    "# Add latitude and longitude to the dataframe\n",
    "predictions_df.loc[:, 'Longitude'] = lons\n",
    "predictions_df.loc[:, 'Latitude'] = lats\n",
    "predictions_df = predictions_df.dropna(subset=['Longitude', 'Latitude', 'MaxTemp'])\n",
    "\n",
    "# Extract data\n",
    "lons = predictions_df['Longitude'].values\n",
    "lats = predictions_df['Latitude'].values\n",
    "max_temp = predictions_df['MaxTemp'].values\n",
    "min_temp = predictions_df['MinTemp'].values\n",
    "rainfall = predictions_df['Rainfall'].values\n",
    "\n",
    "# Get the date from the predictions_df\n",
    "forecast_date = predictions_df['Date'].iloc[0]  # Assuming 'Date' column exists and is consistent\n",
    "\n",
    "# Function to create interpolation map\n",
    "def create_interpolation_map(ax, lons, lats, values, title, cmap, cbar_label):\n",
    "    # Define a grid for interpolation\n",
    "    lon_min, lon_max = lons.min() - 1, lons.max() + 1\n",
    "    lat_min, lat_max = lats.min() - 1, lats.max() + 1\n",
    "    lon_grid, lat_grid = np.meshgrid(\n",
    "        np.linspace(lon_min, lon_max, 200),\n",
    "        np.linspace(lat_min, lat_max, 200)\n",
    "    )\n",
    "\n",
    "    # Perform Ordinary Kriging\n",
    "    krige = OrdinaryKriging(lons, lats, values, variogram_model='linear')\n",
    "    grid, _ = krige.execute('grid', lon_grid[0], lat_grid[:, 0])\n",
    "\n",
    "    # Add features to the map\n",
    "    ax.add_feature(cfeature.COASTLINE, edgecolor='black')\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "    ax.add_feature(cfeature.STATES, linestyle=':', edgecolor='gray')\n",
    "\n",
    "    # Plot interpolated values\n",
    "    contour = ax.contourf(\n",
    "        lon_grid, lat_grid, grid,\n",
    "        levels=20, cmap=cmap, transform=ccrs.PlateCarree()\n",
    "    )\n",
    "\n",
    "    # Add data points\n",
    "    ax.scatter(lons, lats, edgecolors='k', s=50, label='Locations', c='white', transform=ccrs.PlateCarree())\n",
    "\n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(contour, ax=ax, orientation='vertical')\n",
    "    cbar.set_label(cbar_label)  # Colorbar only, no black label on map\n",
    "    ax.set_title(title)\n",
    "\n",
    "# Create side-by-side maps\n",
    "fig, axes = plt.subplots(1, 3, figsize=(22, 8), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "create_interpolation_map(axes[0], lons, lats, max_temp, \"Max Temperature (°C)\", 'coolwarm', 'Temperature (°C)')\n",
    "create_interpolation_map(axes[1], lons, lats, min_temp, \"Min Temperature (°C)\", 'viridis', 'Temperature (°C)')\n",
    "create_interpolation_map(axes[2], lons, lats, rainfall, \"Rainfall (mm)\", 'Blues', 'Rainfall (mm)')\n",
    "\n",
    "# Add a descriptive label for the entire figure\n",
    "fig.text(0.5, 0.02, f\"Weather Forecast for Australia on {forecast_date}\", ha='center', fontsize=14)\n",
    "\n",
    "# Adjust layout: Add space between the maps\n",
    "plt.subplots_adjust(wspace=5)  # Increase wspace to add spacing between maps\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout(rect=[0, 0.04, 1, 1])  # Leave space for the bottom label\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0554462c",
   "metadata": {},
   "source": [
    "## Climate diagrams (10 year period)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53837901",
   "metadata": {},
   "source": [
    "### X.1 Sydney weather station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e293eded",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "## Sydney weather station\n",
    "\n",
    "# combining year, month, and day into a single Date column\n",
    "df_map['Date'] = pd.to_datetime(df_map[['Year', 'Month', 'Day']])\n",
    "\n",
    "# filtering for Sydney weather station and the required time period\n",
    "df_sydney = df_map[(df_map['Location'] == 'Sydney') & (df_map['Date'].dt.year >= 2007) & (df_map['Date'].dt.year <= 2017)]\n",
    "\n",
    "# Sort data by date\n",
    "df_sydney = df_sydney.sort_values(by='Date')\n",
    "\n",
    "# Calculate average temperature\n",
    "df_sydney['AvgTemp'] = (df_sydney['MaxTemp'] + df_sydney['MinTemp']) / 2 \n",
    "df_sydney['YearMonth'] = df_sydney['Date'].dt.to_period('M')\n",
    "\n",
    "# Aggregate monthly data\n",
    "monthly_data = df_sydney.groupby('YearMonth').agg(\n",
    "    MonthlyMaxTemp=('MaxTemp', 'mean'),\n",
    "    MonthlyMinTemp=('MinTemp', 'mean'),\n",
    "    MonthlyAvgTemp=('AvgTemp', 'mean'),\n",
    "    TotalRainfall=('Rainfall', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Convert YearMonth to a datetime for plotting\n",
    "monthly_data['YearMonth'] = monthly_data['YearMonth'].dt.to_timestamp()\n",
    "\n",
    "# Smooth data using a rolling window\n",
    "monthly_data['SmoothedMaxTemp'] = monthly_data['MonthlyMaxTemp'].rolling(window=3, center=True).mean()\n",
    "monthly_data['SmoothedMinTemp'] = monthly_data['MonthlyMinTemp'].rolling(window=3, center=True).mean()\n",
    "monthly_data['SmoothedAvgTemp'] = monthly_data['MonthlyAvgTemp'].rolling(window=3, center=True).mean()\n",
    "\n",
    "# Prepare data for linear regression\n",
    "monthly_data['NumericTime'] = np.arange(len(monthly_data))  # Numeric time for regression (e.g., 0, 1, 2,...)\n",
    "X = monthly_data[['NumericTime']]\n",
    "y = monthly_data['MonthlyAvgTemp']\n",
    "\n",
    "# Fit the linear regression model\n",
    "reg = LinearRegression()\n",
    "reg.fit(X, y)\n",
    "\n",
    "# Predict the trend line\n",
    "monthly_data['TrendLine'] = reg.predict(X)\n",
    "\n",
    "# Set up the figure and axes\n",
    "fig, ax1 = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Plot Smoothed MaxTemp, MinTemp, and AvgTemp as line plots, also overlay regression trend line\n",
    "ax1.plot(monthly_data['YearMonth'], monthly_data['SmoothedMaxTemp'], label='Smoothed max. temperature (°C)', color='red', linewidth=1)\n",
    "ax1.plot(monthly_data['YearMonth'], monthly_data['SmoothedMinTemp'], label='Smoothed min. temperature (°C)', color='blue', linewidth=1)\n",
    "ax1.plot(monthly_data['YearMonth'], monthly_data['SmoothedAvgTemp'], label='Smoothed average temperature (°C)', color='green', linewidth=1)\n",
    "ax1.plot(monthly_data['YearMonth'], monthly_data['TrendLine'], label='Average temperature trend line', color='purple', linestyle='--', linewidth=1.5)\n",
    "\n",
    "# Customize primary Y-axis (temperature)\n",
    "ax1.set_xlabel('Year', fontsize=12)\n",
    "ax1.set_ylabel('Temperature (°C)', fontsize=12)\n",
    "ax1.legend(loc='upper left')\n",
    "ax1.grid(alpha=0.5)\n",
    "\n",
    "# Create a secondary Y-axis for Rainfall\n",
    "ax2 = ax1.twinx()\n",
    "ax2.bar(\n",
    "    monthly_data['YearMonth'], \n",
    "    monthly_data['TotalRainfall'], \n",
    "    color='gray', alpha=0.6, label='Monthly rainfall (mm)', width=20\n",
    ")\n",
    "\n",
    "# Customize secondary Y-axis (rainfall)\n",
    "ax2.set_ylabel('Rainfall (mm)', fontsize=12)\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "# Title and layout adjustments\n",
    "plt.title('Weather trends in Sydney (2007–2017)', fontsize=16)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Print regression results\n",
    "print(f\"Slope of the trend line: {reg.coef_[0]:.4f}\")\n",
    "print(f\"Intercept of the trend line: {reg.intercept_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d69879e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driest year: 2017 with 865.80 mm of rainfall\n",
      "Wettest month: 2015-04 with 366.80 mm of rainfall\n",
      "Hottest year: 2017 with an average temperature of 20.76 °C\n",
      "Coldest year: 2008 with an average temperature of 17.71 °C\n",
      "Monthly averages:\n",
      "-------------------------\n",
      "        AvgTemp  Rainfall\n",
      "Date                     \n",
      "1     23.916846  3.127599\n",
      "2     23.533529  4.323922\n",
      "3     22.369355  4.483871\n",
      "4     19.443309  5.194815\n",
      "5     16.632097  2.434194\n",
      "6     14.436441  5.834014\n",
      "7     13.489068  2.853047\n",
      "8     14.535842  2.156272\n",
      "9     17.309480  1.817844\n",
      "10    19.123656  2.164029\n",
      "11    21.156877  2.913534\n",
      "12    22.213415  2.391935\n"
     ]
    }
   ],
   "source": [
    "# Driest year\n",
    "driest_year = (\n",
    "    df_sydney.groupby(df_sydney['Date'].dt.year)['Rainfall'].sum()\n",
    "    .idxmin()\n",
    ")\n",
    "driest_year_rainfall = df_sydney.groupby(df_sydney['Date'].dt.year)['Rainfall'].sum().min()\n",
    "\n",
    "# Wettest month\n",
    "wettest_month = (\n",
    "    df_sydney.groupby(df_sydney['Date'].dt.to_period('M'))['Rainfall'].sum()\n",
    "    .idxmax()\n",
    ")\n",
    "wettest_month_rainfall = df_sydney.groupby(df_sydney['Date'].dt.to_period('M'))['Rainfall'].sum().max()\n",
    "\n",
    "# Hottest year\n",
    "hottest_year = (\n",
    "    df_sydney.groupby(df_sydney['Date'].dt.year)['AvgTemp'].mean()\n",
    "    .idxmax()\n",
    ")\n",
    "hottest_year_temp = df_sydney.groupby(df_sydney['Date'].dt.year)['AvgTemp'].mean().max()\n",
    "\n",
    "# Coldest year\n",
    "coldest_year = (\n",
    "    df_sydney.groupby(df_sydney['Date'].dt.year)['AvgTemp'].mean()\n",
    "    .idxmin()\n",
    ")\n",
    "coldest_year_temp = df_sydney.groupby(df_sydney['Date'].dt.year)['AvgTemp'].mean().min()\n",
    "\n",
    "# Monthly averages across all years\n",
    "monthly_avg = (\n",
    "    df_sydney.groupby(df_sydney['Date'].dt.month)[['AvgTemp', 'Rainfall']].mean()\n",
    ")\n",
    "\n",
    "# Display statistics\n",
    "print(f\"Driest year: {driest_year} with {driest_year_rainfall:.2f} mm of rainfall\")\n",
    "print(f\"Wettest month: {wettest_month} with {wettest_month_rainfall:.2f} mm of rainfall\")\n",
    "print(f\"Hottest year: {hottest_year} with an average temperature of {hottest_year_temp:.2f} °C\")\n",
    "print(f\"Coldest year: {coldest_year} with an average temperature of {coldest_year_temp:.2f} °C\")\n",
    "print(\"Monthly averages:\")\n",
    "print('-------------------------')\n",
    "print(monthly_avg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b44be48",
   "metadata": {},
   "source": [
    "## X.2 Darwin weather station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b008b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "## Darwuin weather station\n",
    "\n",
    "# combining year, month, and day into a single Date column\n",
    "df_map['Date'] = pd.to_datetime(df_map[['Year', 'Month', 'Day']])\n",
    "\n",
    "# filtering for Darwin weather station and the required time period\n",
    "df_darwin = df_map[(df_map['Location'] == 'Darwin') & (df_map['Date'].dt.year >= 2007) & (df_map['Date'].dt.year <= 2017)]\n",
    "\n",
    "# Sort data by date\n",
    "df_darwin = df_darwin.sort_values(by='Date')\n",
    "\n",
    "# Calculate average temperature\n",
    "df_darwin['AvgTemp'] = (df_darwin['MaxTemp'] + df_darwin['MinTemp']) / 2 \n",
    "df_darwin['YearMonth'] = df_darwin['Date'].dt.to_period('M')\n",
    "\n",
    "# Aggregate monthly data\n",
    "monthly_data = df_darwin.groupby('YearMonth').agg(\n",
    "    MonthlyMaxTemp=('MaxTemp', 'mean'),\n",
    "    MonthlyMinTemp=('MinTemp', 'mean'),\n",
    "    MonthlyAvgTemp=('AvgTemp', 'mean'),\n",
    "    TotalRainfall=('Rainfall', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Convert YearMonth to a datetime for plotting\n",
    "monthly_data['YearMonth'] = monthly_data['YearMonth'].dt.to_timestamp()\n",
    "\n",
    "# Smooth data using a rolling window\n",
    "monthly_data['SmoothedMaxTemp'] = monthly_data['MonthlyMaxTemp'].rolling(window=3, center=True).mean()\n",
    "monthly_data['SmoothedMinTemp'] = monthly_data['MonthlyMinTemp'].rolling(window=3, center=True).mean()\n",
    "monthly_data['SmoothedAvgTemp'] = monthly_data['MonthlyAvgTemp'].rolling(window=3, center=True).mean()\n",
    "\n",
    "# Prepare data for linear regression\n",
    "monthly_data['NumericTime'] = np.arange(len(monthly_data))  # Numeric time for regression (e.g., 0, 1, 2,...)\n",
    "X = monthly_data[['NumericTime']]\n",
    "y = monthly_data['MonthlyAvgTemp']\n",
    "\n",
    "# Fit the linear regression model\n",
    "reg = LinearRegression()\n",
    "reg.fit(X, y)\n",
    "\n",
    "# Predict the trend line\n",
    "monthly_data['TrendLine'] = reg.predict(X)\n",
    "\n",
    "# Set up the figure and axes\n",
    "fig, ax1 = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Plot Smoothed MaxTemp, MinTemp, and AvgTemp as line plots, also overlay regression trend line\n",
    "ax1.plot(monthly_data['YearMonth'], monthly_data['SmoothedMaxTemp'], label='Smoothed max. temperature (°C)', color='red', linewidth=1)\n",
    "ax1.plot(monthly_data['YearMonth'], monthly_data['SmoothedMinTemp'], label='Smoothed min. temperature (°C)', color='blue', linewidth=1)\n",
    "ax1.plot(monthly_data['YearMonth'], monthly_data['SmoothedAvgTemp'], label='Smoothed average temperature (°C)', color='green', linewidth=1)\n",
    "ax1.plot(monthly_data['YearMonth'], monthly_data['TrendLine'], label='Average temperature trend line', color='purple', linestyle='--', linewidth=1.5)\n",
    "\n",
    "# Customize primary Y-axis (temperature)\n",
    "ax1.set_xlabel('Year', fontsize=12)\n",
    "ax1.set_ylabel('Temperature (°C)', fontsize=12)\n",
    "ax1.legend(loc='upper left')\n",
    "ax1.grid(alpha=0.5)\n",
    "\n",
    "# Create a secondary Y-axis for Rainfall\n",
    "ax2 = ax1.twinx()\n",
    "ax2.bar(\n",
    "    monthly_data['YearMonth'], \n",
    "    monthly_data['TotalRainfall'], \n",
    "    color='gray', alpha=0.6, label='Monthly rainfall (mm)', width=20\n",
    ")\n",
    "\n",
    "# Customize secondary Y-axis (rainfall)\n",
    "ax2.set_ylabel('Rainfall (mm)', fontsize=12)\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "# Title and layout adjustments\n",
    "plt.title('Weather trends in Darwin (2007–2017)', fontsize=16)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Print regression results\n",
    "print(f\"Slope of the trend line: {reg.coef_[0]:.4f}\")\n",
    "print(f\"Intercept of the trend line: {reg.intercept_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafab1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Driest year\n",
    "driest_year = (\n",
    "    df_darwin.groupby(df_darwin['Date'].dt.year)['Rainfall'].sum()\n",
    "    .idxmin()\n",
    ")\n",
    "driest_year_rainfall = df_darwin.groupby(df_sydney['Date'].dt.year)['Rainfall'].sum().min()\n",
    "\n",
    "# Wettest month\n",
    "wettest_month = (\n",
    "    df_darwiny.groupby(df_darwin['Date'].dt.to_period('M'))['Rainfall'].sum()\n",
    "    .idxmax()\n",
    ")\n",
    "wettest_month_rainfall = df_darwin.groupby(df_darwin['Date'].dt.to_period('M'))['Rainfall'].sum().max()\n",
    "\n",
    "# Hottest year\n",
    "hottest_year = (\n",
    "    df_darwin.groupby(df_darwin['Date'].dt.year)['AvgTemp'].mean()\n",
    "    .idxmax()\n",
    ")\n",
    "hottest_year_temp = df_darwin.groupby(df_sydney['Date'].dt.year)['AvgTemp'].mean().max()\n",
    "\n",
    "# Coldest year\n",
    "coldest_year = (\n",
    "    df_darwin.groupby(df_darwin['Date'].dt.year)['AvgTemp'].mean()\n",
    "    .idxmin()\n",
    ")\n",
    "coldest_year_temp = df_darwin.groupby(df_darwiny['Date'].dt.year)['AvgTemp'].mean().min()\n",
    "\n",
    "# Monthly averages across all years\n",
    "monthly_avg = (\n",
    "    df_sydney.groupby(df_sydney['Date'].dt.month)[['AvgTemp', 'Rainfall']].mean()\n",
    ")\n",
    "\n",
    "# Display statistics\n",
    "print(f\"Driest year: {driest_year} with {driest_year_rainfall:.2f} mm of rainfall\")\n",
    "print(f\"Wettest month: {wettest_month} with {wettest_month_rainfall:.2f} mm of rainfall\")\n",
    "print(f\"Hottest year: {hottest_year} with an average temperature of {hottest_year_temp:.2f} °C\")\n",
    "print(f\"Coldest year: {coldest_year} with an average temperature of {coldest_year_temp:.2f} °C\")\n",
    "print(\"Monthly averages:\")\n",
    "print('-------------------------')\n",
    "print(monthly_avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54b651ee-519e-4654-83f1-89549b485f78",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3805\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3806\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26512\\3109195846.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#võrdlus reaalsete andmetega ennustuse kuupäeval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mpredictions_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4101\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4102\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4103\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3810\u001b[0m             ):\n\u001b[0;32m   3811\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3812\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3813\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3814\u001b[0m             \u001b[1;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Date'"
     ]
    }
   ],
   "source": [
    "## evaluation\n",
    "\n",
    "#võrdlus reaalsete andmetega ennustuse kuupäeval\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "predictions_df['Date'] = pd.to_datetime(predictions_df['Date'])\n",
    "\n",
    "# Merge the dataframes on 'Date' and 'Location'\n",
    "comparison_df = pd.merge(\n",
    "    predictions_df, \n",
    "    df, \n",
    "    on=['Date', 'Location'], \n",
    "    suffixes=('_predicted', '_actual')\n",
    ")\n",
    "\n",
    "# Calculate differences\n",
    "comparison_df['MinTemp_Diff'] = comparison_df['MinTemp_predicted'] - comparison_df['MinTemp_actual']\n",
    "comparison_df['MaxTemp_Diff'] = comparison_df['MaxTemp_predicted'] - comparison_df['MaxTemp_actual']\n",
    "comparison_df['Rainfall_Diff'] = comparison_df['Rainfall_predicted'] - comparison_df['Rainfall_actual']\n",
    "\n",
    "# Group by location and summarize the differences\n",
    "summary = comparison_df.groupby('Location').agg({\n",
    "    'MinTemp_Diff': ['mean'],\n",
    "    'MaxTemp_Diff': ['mean'],\n",
    "    'Rainfall_Diff': ['mean']\n",
    "})\n",
    "\n",
    "# Reset index for easy viewing\n",
    "summary = summary.reset_index()\n",
    "\n",
    "prediction_date= predictions_df['Date'].iloc[1]\n",
    "# Display the summary\n",
    "print(f\"Comparison of Predictions vs Actual Weather by Location on {prediction_date}\" )\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a458b08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
